{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Building a GPT\n",
    "<a href=\"https://colab.research.google.com/github/NikiforovG/gpt/blob/main/main/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ],
   "metadata": {
    "id": "wJpXpmjEYC_T"
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "COLAB = False"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T13:46:03.046398Z",
     "start_time": "2024-03-28T13:46:03.035390Z"
    }
   },
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if COLAB:\n",
    "    if os.getcwd() != '/content/gpt/main':\n",
    "        !git clone https://github.com/NikiforovG/gpt.git\n",
    "        !cd diffusion-models-basics\n",
    "        # !git checkout gpt\n",
    "        os.chdir('/content/gpt/main')\n",
    "\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount('/content/drive')\n",
    "    folder = '/content/drive/MyDrive/Colab Notebooks/gpt/'\n",
    "else:\n",
    "    folder = './'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T13:46:03.124904Z",
     "start_time": "2024-03-28T13:46:03.114615Z"
    }
   },
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "weights_folder = os.path.join(folder, 'weights/')\n",
    "os.makedirs(weights_folder, exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T13:46:03.171698Z",
     "start_time": "2024-03-28T13:46:03.162649Z"
    }
   },
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "import torch\n",
    "\n",
    "from src.data import Data, Vocabulary\n",
    "from src.gpt import GPTConfig, GPTModel\n",
    "from src.utils import (\n",
    "    count_parameters,\n",
    "    estimate_loss,\n",
    "    get_tinyshakespeare_dataset,\n",
    "    load_training_state,\n",
    "    save_training_state,\n",
    "    TrainingState,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T13:46:07.190480Z",
     "start_time": "2024-03-28T13:46:03.179917Z"
    }
   },
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else torch.device('cpu'))\n",
    "print('device:', device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T13:46:07.204742Z",
     "start_time": "2024-03-28T13:46:07.193263Z"
    }
   },
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data preparation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "text = get_tinyshakespeare_dataset()"
   ],
   "metadata": {
    "id": "O6medjfRsLD9",
    "ExecuteTime": {
     "end_time": "2024-03-28T13:46:07.592096Z",
     "start_time": "2024-03-28T13:46:07.207784Z"
    }
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"length of dataset in characters: \", len(text))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6xWI_VyAsN8F",
    "outputId": "ed819dd0-72e5-40a6-d2ed-928ff73bfda6",
    "ExecuteTime": {
     "end_time": "2024-03-28T13:46:07.608601Z",
     "start_time": "2024-03-28T13:46:07.604014Z"
    }
   },
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters:  1115394\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# let's look at the first 1000 characters\n",
    "print(text[:1000])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2c5V0FvqseE0",
    "outputId": "25ca7adc-b8c0-42d1-b08c-e0863c5c314e",
    "ExecuteTime": {
     "end_time": "2024-03-28T13:46:07.625126Z",
     "start_time": "2024-03-28T13:46:07.613106Z"
    }
   },
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# here are all the unique characters that occur in this text\n",
    "vocab = Vocabulary(text=text)\n",
    "print(''.join(vocab.stoi.keys()))\n",
    "print(vocab.size)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0e-Rbyr8sfM8",
    "outputId": "f34e94a9-5b44-4cf3-885b-986731929109",
    "ExecuteTime": {
     "end_time": "2024-03-28T13:46:07.658274Z",
     "start_time": "2024-03-28T13:46:07.629807Z"
    }
   },
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "65\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(vocab.encode(\"hii there\"))\n",
    "print(vocab.decode(vocab.encode(\"hii there\")))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yw1LKNCgwjj1",
    "outputId": "86fcc21c-2cf7-40d9-cd7b-b5a253da4459",
    "ExecuteTime": {
     "end_time": "2024-03-28T13:46:07.671696Z",
     "start_time": "2024-03-28T13:46:07.663240Z"
    }
   },
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 47, 47, 1, 58, 46, 43, 56, 43]\n",
      "hii there\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# let's now encode the entire text dataset and store it into a torch.Tensor\n",
    "data = Data(vocab.encode(text))\n",
    "print(data.train_data.shape, data.train_data.dtype)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YJb0OXPwzvqg",
    "outputId": "db7297cc-36a9-4fae-e941-e7bb9e0e91d1",
    "ExecuteTime": {
     "end_time": "2024-03-28T13:46:07.938827Z",
     "start_time": "2024-03-28T13:46:07.674185Z"
    }
   },
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([892315]) torch.int64\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "continue_training = True"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T13:46:07.950802Z",
     "start_time": "2024-03-28T13:46:07.944482Z"
    }
   },
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "if continue_training:\n",
    "    training_state = load_training_state(weights_folder)\n",
    "    model_config = training_state.model_config\n",
    "    model = training_state.model\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters())\n",
    "    optimizer.load_state_dict(training_state.optimizer_state_dict)\n",
    "\n",
    "    steps_done = training_state.training_steps\n",
    "    training_time_done = training_state.training_time\n",
    "else:\n",
    "    steps_done = 0\n",
    "    training_time_done = 0\n",
    "\n",
    "    # Model\n",
    "    block_size = 8\n",
    "    emb_size = 32\n",
    "    num_heads = 4\n",
    "    num_layers = 3\n",
    "    dropout = 0.2\n",
    "\n",
    "    # Optimizer\n",
    "    learning_rate = 1e-3\n",
    "\n",
    "    model_config = GPTConfig(\n",
    "        vocab_size=vocab.size,\n",
    "        block_size=block_size,\n",
    "        emb_size=emb_size,\n",
    "        num_heads=num_heads,\n",
    "        num_layers=num_layers,\n",
    "        dropout=dropout,\n",
    "    )\n",
    "    model = GPTModel(config=model_config).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T13:46:24.547012Z",
     "start_time": "2024-03-28T13:46:24.495972Z"
    }
   },
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "source": [
    "print(f'models has {count_parameters(model)} parameters')\n",
    "print(vocab.decode(model.generate(start_tokens=torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nql_1ER53oCf",
    "outputId": "5de90b1b-4603-428a-f571-fe4bd3c45436",
    "ExecuteTime": {
     "end_time": "2024-03-28T13:46:45.501275Z",
     "start_time": "2024-03-28T13:46:29.917532Z"
    }
   },
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models has 42369 parameters\n",
      "\n",
      "And attherature bet't ing anchiked:\n",
      "Unk so shem his ofay, wittexelsoned's unt feinst. Wem inlomy or,\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Training\n",
    "batch_size = 32\n",
    "max_iters = 10000\n",
    "eval_interval = 1000\n",
    "eval_iters = 200"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T13:46:45.557541Z",
     "start_time": "2024-03-28T13:46:45.534729Z"
    }
   },
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "source": [
    "timer = time()\n",
    "steps = 0\n",
    "for steps in range(steps_done + 1, steps_done + 1 + max_iters):\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = data.get_batch('train', block_size=model_config.block_size, batch_size=batch_size)\n",
    "    xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "    optimizer.step()\n",
    "\n",
    "    if steps % eval_interval == 0:\n",
    "        losses = estimate_loss(\n",
    "            eval_iters=eval_iters,\n",
    "            model=model,\n",
    "            data=data,\n",
    "            block_size=model_config.block_size,\n",
    "            batch_size=batch_size,\n",
    "            device=device,\n",
    "        )\n",
    "        print(\n",
    "            f\"step: {steps}; training time: {round(time() - timer)} sec; train loss: {losses['train']:.4f}; val loss: {losses['val']:.4f}\"\n",
    "        )\n",
    "training_time = time() - timer + training_time_done"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hs4kI8YdEkQj",
    "outputId": "42ded55c-2983-4d91-c528-675b2edfa849",
    "ExecuteTime": {
     "end_time": "2024-03-28T13:52:37.902293Z",
     "start_time": "2024-03-28T13:46:45.571500Z"
    }
   },
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 11000; training time: 65 sec; train loss: 1.9972; val loss: 2.0787\n",
      "step: 12000; training time: 96 sec; train loss: 1.9820; val loss: 2.0784\n",
      "step: 13000; training time: 129 sec; train loss: 1.9766; val loss: 2.0680\n",
      "step: 14000; training time: 155 sec; train loss: 1.9696; val loss: 2.0683\n",
      "step: 15000; training time: 182 sec; train loss: 1.9577; val loss: 2.0646\n",
      "step: 16000; training time: 211 sec; train loss: 1.9440; val loss: 2.0599\n",
      "step: 17000; training time: 252 sec; train loss: 1.9504; val loss: 2.0556\n",
      "step: 18000; training time: 283 sec; train loss: 1.9429; val loss: 2.0540\n",
      "step: 19000; training time: 320 sec; train loss: 1.9464; val loss: 2.0497\n",
      "step: 20000; training time: 352 sec; train loss: 1.9275; val loss: 2.0622\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "training_state = TrainingState(\n",
    "    model_config=model_config,\n",
    "    model=model,\n",
    "    optimizer_state_dict=optimizer.state_dict(),\n",
    "    training_time=training_time,\n",
    "    training_steps=steps,\n",
    ")\n",
    "save_training_state(weights_folder, training_state)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T13:52:37.934773Z",
     "start_time": "2024-03-28T13:52:37.905591Z"
    }
   },
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "source": [
    "sample_generation = vocab.decode(\n",
    "    model.generate(start_tokens=torch.zeros((1, 1), dtype=torch.long), max_new_tokens=500)[0].tolist()\n",
    ")\n",
    "print(sample_generation)\n",
    "with open(os.path.join(weights_folder, f'gpt_{steps}_sample_output.txt'), 'w') as f:\n",
    "    f.write(sample_generation)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EcVIDWAZEtjN",
    "outputId": "0ad6f9d2-ad58-4498-a5f8-6f31407bb18b",
    "ExecuteTime": {
     "end_time": "2024-03-28T13:52:40.511309Z",
     "start_time": "2024-03-28T13:52:37.936359Z"
    }
   },
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "the should th land sament cart'r do;\n",
      "Freat,\n",
      "As hath, have a me pance,\n",
      "If hervo norme: and ared the cablemear there\n",
      "CHonot ourmb Ricary dacryness! hen, I and I ributh truep wourse I fyour me shoubdee! that lore fort in OF AMING\n",
      "To it themb our wonsself't the ceen!\n",
      "Ands ark I I bon I knows mist, be hobreath.\n",
      "\n",
      "HARd murtes midend How?\n",
      "Seyquore thou, good Shy devence infued?\n",
      "\n",
      "HENRY VI:\n",
      "That cres, she\n",
      "Maith\n",
      "To mist lad VONTHESTIL:\n",
      "And way let butt?\n",
      "\n",
      "And that dill set wellf.\n",
      "\n",
      "INA:\n",
      "I am your upon cany t\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
