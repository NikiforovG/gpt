{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Building a GPT\n",
    "<a href=\"https://colab.research.google.com/github/NikiforovG/gpt/blob/master/main/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ],
   "metadata": {
    "id": "wJpXpmjEYC_T"
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "COLAB = False"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T15:53:30.233991Z",
     "start_time": "2024-03-28T15:53:30.218138Z"
    }
   },
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if COLAB:\n",
    "    if os.getcwd() != '/content/gpt/main':\n",
    "        !pip install einops\n",
    "        !git clone https://github.com/NikiforovG/gpt.git\n",
    "        # !cd gpt\n",
    "        # !git checkout gpt\n",
    "        os.chdir('/content/gpt/main')\n",
    "\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount('/content/drive')\n",
    "    folder = '/content/drive/MyDrive/Colab Notebooks/gpt/'\n",
    "else:\n",
    "    folder = './'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T15:53:30.281390Z",
     "start_time": "2024-03-28T15:53:30.264651Z"
    }
   },
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "weights_folder = os.path.join(folder, 'weights/')\n",
    "os.makedirs(weights_folder, exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T15:53:30.303139Z",
     "start_time": "2024-03-28T15:53:30.290887Z"
    }
   },
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "import torch\n",
    "\n",
    "from src.data import Data, Vocabulary\n",
    "from src.gpt import GPTConfig, GPTModel\n",
    "from src.utils import (\n",
    "    count_parameters,\n",
    "    estimate_loss,\n",
    "    get_tinyshakespeare_dataset,\n",
    "    load_training_state,\n",
    "    save_training_state,\n",
    "    TrainingState,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T15:53:33.489361Z",
     "start_time": "2024-03-28T15:53:30.308579Z"
    }
   },
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else torch.device('cpu'))\n",
    "print('device:', device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T15:53:33.498692Z",
     "start_time": "2024-03-28T15:53:33.492711Z"
    }
   },
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data preparation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "text = get_tinyshakespeare_dataset()"
   ],
   "metadata": {
    "id": "O6medjfRsLD9",
    "ExecuteTime": {
     "end_time": "2024-03-28T15:53:33.690473Z",
     "start_time": "2024-03-28T15:53:33.500936Z"
    }
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"length of dataset in characters: \", len(text))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6xWI_VyAsN8F",
    "outputId": "ed819dd0-72e5-40a6-d2ed-928ff73bfda6",
    "ExecuteTime": {
     "end_time": "2024-03-28T15:53:33.704867Z",
     "start_time": "2024-03-28T15:53:33.698478Z"
    }
   },
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters:  1115394\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# let's look at the first 1000 characters\n",
    "print(text[:1000])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2c5V0FvqseE0",
    "outputId": "25ca7adc-b8c0-42d1-b08c-e0863c5c314e",
    "ExecuteTime": {
     "end_time": "2024-03-28T15:53:33.715508Z",
     "start_time": "2024-03-28T15:53:33.709184Z"
    }
   },
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# here are all the unique characters that occur in this text\n",
    "vocab = Vocabulary(text=text)\n",
    "print(''.join(vocab.stoi.keys()))\n",
    "print(vocab.size)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0e-Rbyr8sfM8",
    "outputId": "f34e94a9-5b44-4cf3-885b-986731929109",
    "ExecuteTime": {
     "end_time": "2024-03-28T15:53:33.743973Z",
     "start_time": "2024-03-28T15:53:33.721002Z"
    }
   },
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "65\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(vocab.encode(\"hii there\"))\n",
    "print(vocab.decode(vocab.encode(\"hii there\")))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yw1LKNCgwjj1",
    "outputId": "86fcc21c-2cf7-40d9-cd7b-b5a253da4459",
    "ExecuteTime": {
     "end_time": "2024-03-28T15:53:33.772536Z",
     "start_time": "2024-03-28T15:53:33.765689Z"
    }
   },
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 47, 47, 1, 58, 46, 43, 56, 43]\n",
      "hii there\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# let's now encode the entire text dataset and store it into a torch.Tensor\n",
    "data = Data(vocab.encode(text))\n",
    "print(data.train_data.shape, data.train_data.dtype)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YJb0OXPwzvqg",
    "outputId": "db7297cc-36a9-4fae-e941-e7bb9e0e91d1",
    "ExecuteTime": {
     "end_time": "2024-03-28T15:53:34.003281Z",
     "start_time": "2024-03-28T15:53:33.778911Z"
    }
   },
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([892315]) torch.int64\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "continue_training = False"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T15:53:34.009066Z",
     "start_time": "2024-03-28T15:53:34.004974Z"
    }
   },
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "if continue_training:\n",
    "    training_state = load_training_state(weights_folder)\n",
    "    model_config = training_state.model_config\n",
    "    model = training_state.model\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters())\n",
    "    optimizer.load_state_dict(training_state.optimizer_state_dict)\n",
    "\n",
    "    steps_done = training_state.training_steps\n",
    "    training_time_done = training_state.training_time\n",
    "else:\n",
    "    steps_done = 0\n",
    "    training_time_done = 0\n",
    "\n",
    "    # Model\n",
    "    block_size = 8\n",
    "    emb_size = 32\n",
    "    num_heads = 4\n",
    "    num_layers = 3\n",
    "    dropout = 0.2\n",
    "\n",
    "    # Optimizer\n",
    "    learning_rate = 1e-3\n",
    "\n",
    "    model_config = GPTConfig(\n",
    "        vocab_size=vocab.size,\n",
    "        block_size=block_size,\n",
    "        emb_size=emb_size,\n",
    "        num_heads=num_heads,\n",
    "        num_layers=num_layers,\n",
    "        dropout=dropout,\n",
    "    )\n",
    "    model = GPTModel(config=model_config).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T15:53:36.018042Z",
     "start_time": "2024-03-28T15:53:34.017053Z"
    }
   },
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": [
    "print(f'models has {count_parameters(model)} parameters')\n",
    "print(vocab.decode(model.generate(start_tokens=torch.zeros((1, 1), dtype=torch.long, device=device), max_new_tokens=100)[0].tolist()))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nql_1ER53oCf",
    "outputId": "5de90b1b-4603-428a-f571-fe4bd3c45436",
    "ExecuteTime": {
     "end_time": "2024-03-28T15:53:36.714739Z",
     "start_time": "2024-03-28T15:53:36.020187Z"
    }
   },
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models has 42369 parameters\n",
      "\n",
      "gi;cT;NJbYlA C YyM&qONQTKVEM!HC3&bfdOf'Iv$&-Ik'a.hAh,lEzaT-y&b&Lku ,sPNE.APYHEpuEMmTkm-gRlcw&gMKMgro\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Training\n",
    "batch_size = 32\n",
    "max_iters = 10000\n",
    "eval_interval = 1000\n",
    "eval_iters = 200"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T15:53:36.723837Z",
     "start_time": "2024-03-28T15:53:36.717816Z"
    }
   },
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def eval_model():\n",
    "    losses = estimate_loss(\n",
    "        eval_iters=eval_iters,\n",
    "        model=model,\n",
    "        data=data,\n",
    "        block_size=model_config.block_size,\n",
    "        batch_size=batch_size,\n",
    "        device=device,\n",
    "    )\n",
    "    print(\n",
    "        f\"step: {steps}; training time: {round(time() - timer)} sec; train loss: {losses['train']:.4f}; val loss: {losses['val']:.4f}\"\n",
    "    )\n",
    "    training_state = TrainingState(\n",
    "        model_config=model_config,\n",
    "        model=model,\n",
    "        optimizer_state_dict=optimizer.state_dict(),\n",
    "        training_time=round(time() - timer),\n",
    "        training_steps=steps,\n",
    "    )\n",
    "    save_training_state(weights_folder, training_state)\n",
    "    sample_generation = vocab.decode(\n",
    "        model.generate(start_tokens=torch.zeros((1, 1), dtype=torch.long, device=device), max_new_tokens=500)[0].tolist()\n",
    "    )\n",
    "    with open(os.path.join(weights_folder, f'gpt_{steps}_sample_output.txt'), 'w') as f:\n",
    "        f.write(sample_generation)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T15:53:36.739292Z",
     "start_time": "2024-03-28T15:53:36.726981Z"
    }
   },
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "source": [
    "timer = time()\n",
    "steps = 0\n",
    "for steps in range(steps_done + 1, steps_done + 1 + max_iters):\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = data.get_batch('train', block_size=model_config.block_size, batch_size=batch_size)\n",
    "    xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "    optimizer.step()\n",
    "\n",
    "    if steps % eval_interval == 0:\n",
    "        eval_model()\n",
    "training_time = round(time() - timer) + training_time_done\n",
    "print(f\"Total training time {training_time} sec\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hs4kI8YdEkQj",
    "outputId": "42ded55c-2983-4d91-c528-675b2edfa849",
    "ExecuteTime": {
     "end_time": "2024-03-28T15:58:22.049372Z",
     "start_time": "2024-03-28T15:53:36.741930Z"
    }
   },
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1000; training time: 25 sec; train loss: 2.3207; val loss: 2.3629\n",
      "step: 2000; training time: 51 sec; train loss: 2.2262; val loss: 2.2502\n",
      "step: 3000; training time: 77 sec; train loss: 2.1574; val loss: 2.2050\n",
      "step: 4000; training time: 104 sec; train loss: 2.1139; val loss: 2.1720\n",
      "step: 5000; training time: 131 sec; train loss: 2.0788; val loss: 2.1398\n",
      "step: 6000; training time: 158 sec; train loss: 2.0649; val loss: 2.1131\n",
      "step: 7000; training time: 190 sec; train loss: 2.0308; val loss: 2.1134\n",
      "step: 8000; training time: 218 sec; train loss: 2.0265; val loss: 2.0869\n",
      "step: 9000; training time: 245 sec; train loss: 2.0191; val loss: 2.0888\n",
      "step: 10000; training time: 283 sec; train loss: 1.9988; val loss: 2.0823\n",
      "Total training time 285 sec\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 10000; training time: 288 sec; train loss: 1.9948; val loss: 2.0848\n"
     ]
    }
   ],
   "source": [
    "eval_model()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T15:58:26.802775Z",
     "start_time": "2024-03-28T15:58:22.051855Z"
    }
   },
   "execution_count": 18
  }
 ]
}
